[[databuffers]]
= Data Buffers and Codecs

* "ByteBuffer"
	** "java.nio.ByteBuffer"
		*** many libraries -- build their -- own byte buffer API | top
			**** _Example1:_ Netty has the `ByteBuf` hierarchy
			**** _Example2:_ Undertow uses XNIO
			**** _Example3:_ Jetty uses pooled byte buffers + callback / be released
	** uses
		*** network operations
			**** Reason: 🧠 reuse buffers and/or using direct buffers -- is beneficial for -- performance 🧠
	** abstractions / provided by `spring-core` module
		*** xref:core/databuffer-codec.adoc#databuffers-factory[`DataBufferFactory`]
			**** -- abstracts the -- creation of a data buffer
		*** xref:core/databuffer-codec.adoc#databuffers-buffer[`DataBuffer`]
			**** == byte buffer / -- may be -- xref:core/databuffer-codec.adoc#databuffers-buffer-pooled[pooled]
		*** xref:core/databuffer-codec.adoc#databuffers-utils[`DataBufferUtils`]
			**** == utility methods -- for -- data buffers
		*** <<Codecs>>
			**** data buffer streams <- are decode or encoded into -> higher level objects


[[databuffers-factory]]
== `DataBufferFactory`

* uses
	** create data buffers / -- can be done via -- 
		*** new data buffer is allocated /  
			**** capacity upfront is optionally specified
			**** more efficient
				***** even though implementations of `DataBuffer` -- can -- grow & shrink on demand
		*** wrap with a `DataBuffer` implementation, an existing `byte[]` or `java.nio.ByteBuffer` / 
			**** decorates the given data
			**** NOT involve allocation
	** access to it | WebFlux applications
		*** == 👁️ NOT create a `DataBufferFactory` 👁️
		*** -- through the --
			**** `ServerHttpResponse` | client side
			**** `ClientHttpRequest` | client side
		*** type of factory -- depends on the -- underlying client or server ( _Example:_ `NettyDataBufferFactory` | Reactor Netty, `DefaultDataBufferFactory` | others)


[[databuffers-buffer]]
== `DataBuffer`

* := interface /
	** offered operations == offered by `java.nio.ByteBuffer` + few additional benefits
		*** few additional benefits
			**** some -- are inspired by the -- Netty `ByteBuf`
			**** read and write -- with -- independent positions
				***** == to alternate between read and write -> NOT requirred a call to `flip()`
			**** capacity expanded on demand == `java.lang.StringBuilder`
			**** pooled buffers and reference counting -- via -- xref:core/databuffer-codec.adoc#databuffers-buffer-pooled[`PooledDataBuffer`]
			**** view a buffer == `java.nio.ByteBuffer`, `InputStream`, or `OutputStream`
			**** determine the index, or the last index / given byte


[[databuffers-buffer-pooled]]
== `PooledDataBuffer`

* "ByteBuffer" 
	** types
		*** direct
			**** may reside | outside the Java heap / NOT need for copying for native I/O operations
			**** uses
				***** receive and send data -- over a -- socket
			**** expensive to create and release -> consider using pooling buffers
		*** non-direct
	** Check {java-api}/java.base/java/nio/ByteBuffer.html[ByteBuffer]
* `PooledDataBuffer`
	** := extension of `DataBuffer` / -- helps with -- reference counting
		*** reference counting -- is essential for -- byte buffer pooling
	** How does it work?
		*** once `PooledDataBuffer` is allocated -> reference count is at 1
		*** if calls to `retain()` -> the count is +1
		*** if calls to `release()` -> the count is -1
		*** as long as the count is > 0 -> the buffer is guaranteed NOT to be released
		*** once count < 0 -> pooled buffer can be released
			**** == reserved memory for the buffer -- is returned to the -- memory pool
	** ways to operate | it
		*** directly | it
		*** use `DataBufferUtils` / ONLY if it is an instance of `PooledDataBuffer` -> apply release or retain to a `DataBuffer`


[[databuffers-utils]]
== `DataBufferUtils`

* TODO:
`DataBufferUtils` offers a number of utility methods to operate on data buffers:

* Join a stream of data buffers into a single buffer possibly with zero copy, e.g. via
composite buffers, if that's supported by the underlying byte buffer API.
* Turn `InputStream` or NIO `Channel` into `Flux<DataBuffer>`, and vice versa a
`Publisher<DataBuffer>` into `OutputStream` or NIO `Channel`.
* Methods to release or retain a `DataBuffer` if the buffer is an instance of
`PooledDataBuffer`.
* Skip or take from a stream of bytes until a specific byte count.




[[codecs]]
== Codecs

The `org.springframework.core.codec` package provides the following strategy interfaces:

* `Encoder` to encode `Publisher<T>` into a stream of data buffers.
* `Decoder` to decode `Publisher<DataBuffer>` into a stream of higher level objects.

The `spring-core` module provides `byte[]`, `ByteBuffer`, `DataBuffer`, `Resource`, and
`String` encoder and decoder implementations. The `spring-web` module adds Jackson JSON,
Jackson Smile, JAXB2, Protocol Buffers and other encoders and decoders. See
xref:web/webflux/reactive-spring.adoc#webflux-codecs[Codecs] in the WebFlux section.




[[databuffers-using]]
== Using `DataBuffer`

When working with data buffers, special care must be taken to ensure buffers are released
since they may be xref:core/databuffer-codec.adoc#databuffers-buffer-pooled[pooled]. We'll use codecs to illustrate
how that works but the concepts apply more generally. Let's see what codecs must do
internally to manage data buffers.

A `Decoder` is the last to read input data buffers, before creating higher level
objects, and therefore it must release them as follows:

. If a `Decoder` simply reads each input buffer and is ready to
release it immediately, it can do so via `DataBufferUtils.release(dataBuffer)`.
. If a `Decoder` is using `Flux` or `Mono` operators such as `flatMap`, `reduce`, and
others that prefetch and cache data items internally, or is using operators such as
`filter`, `skip`, and others that leave out items, then
`doOnDiscard(DataBuffer.class, DataBufferUtils::release)` must be added to the
composition chain to ensure such buffers are released prior to being discarded, possibly
also as a result of an error or cancellation signal.
. If a `Decoder` holds on to one or more data buffers in any other way, it must
ensure they are released when fully read, or in case of an error or cancellation signals that
take place before the cached data buffers have been read and released.

Note that `DataBufferUtils#join` offers a safe and efficient way to aggregate a data
buffer stream into a single data buffer. Likewise `skipUntilByteCount` and
`takeUntilByteCount` are additional safe methods for decoders to use.

An `Encoder` allocates data buffers that others must read (and release). So an `Encoder`
doesn't have much to do. However an `Encoder` must take care to release a data buffer if
a serialization error occurs while populating the buffer with data. For example:

[tabs]
======
Java::
+
[source,java,indent=0,subs="verbatim,quotes",role="primary"]
----
	DataBuffer buffer = factory.allocateBuffer();
	boolean release = true;
	try {
		// serialize and populate buffer..
		release = false;
	}
	finally {
		if (release) {
			DataBufferUtils.release(buffer);
		}
	}
	return buffer;
----

Kotlin::
+
[source,kotlin,indent=0,subs="verbatim,quotes",role="secondary"]
----
	val buffer = factory.allocateBuffer()
	var release = true
	try {
		// serialize and populate buffer..
		release = false
	} finally {
		if (release) {
			DataBufferUtils.release(buffer)
		}
	}
	return buffer
----
======

The consumer of an `Encoder` is responsible for releasing the data buffers it receives.
In a WebFlux application, the output of the `Encoder` is used to write to the HTTP server
response, or to the client HTTP request, in which case releasing the data buffers is the
responsibility of the code writing to the server response, or to the client request.

Note that when running on Netty, there are debugging options for
https://github.com/netty/netty/wiki/Reference-counted-objects#troubleshooting-buffer-leaks[troubleshooting buffer leaks].
